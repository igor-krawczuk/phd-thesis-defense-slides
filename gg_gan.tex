% !TeX root = presentation.tex
\documentclass[./presentation.tex]{subfiles}
\begin{document}
\begin{frame}[label=working]
  \frametitle{Why does nobody use graphs directly yet? \visible<2->{Desiderata}
  }
  %WHY now and how will we deal with it?=> prepare for benefits of equivaraince
Need a method able to 
\begin{itemize}
    \visible<3->{\item model relations and compositions naturally with...} %GNNs/set networks give this
    \visible<3->{\item compact parametrization...} % GG-GAN gives this, digress *kinda* gives this, hgd does again
    \visible<4->{\item fast sampling...} % and this, digress kinda gives this, hgd gives this
    \visible<5->{\item high fidelity ...} %digress, hgd gives this
    \visible<6->{\item while scaling to netlist sized graphs } % ggg kinda gives this, digress kinda , hgd does
\end{itemize}
\end{frame}
\begin{frame}[label=working]
%% WP1
  \frametitle{Equivariance \& Geometric DL}
  Group action $G$, e.g. Permutation Group.
  Invariant $f(G(x;\theta))=f(x;\theta)$
  Equivariant $f(G(x);\theta)=G(f(x;\theta))$
  Both if we parametrize and learn $f(x;\theta)$, both remove the dependency of $\nabla_\theta f(x)$ from the effect of a group action on $x$$\implies$ the network does not need to learn $G$ as a factor of variation,improving sample complexity for generalizeable learning\citep{elesedyProvablyStrictGeneralisation2021b}, benefit of equivariant parametrization
\end{frame}
\begin{frame}[label=working,t]
  \frametitle{Geometric Graph Generation}
  %need to explain this
  %https://en.wikipedia.org/wiki/Spatial_network
  %threshold graph
  
\end{frame}
\begin{frame}[label=working]
  \frametitle{SotA (Geometric) Graph Generative Models at outset (2019)}
  \begin{itemize}
    \item GraphRNN, GRAN, BiGG: autoregressive likelihood $\implies$ order dependent,high latency%TODO cite the paper that shows that order matters
    \item MolGAN: GAN, non PE generator, fixed size matrix  $\implies$ no size extrapolation,mode collapse
    \item CondGEN: VAE-GAN hybrid, FNN generator $\implies$ VAE limitations \citep{bousquetOptimalTransportGenerative2017a, genevayGANVAEOptimal2017e}%we want to be blind to permutation *once done*; during *training* we can impose orderings/identities as long as it happens in the latent state and agnostic to the data?
  \end{itemize}
\end{frame}

%PROBLEM: no big graphs=> why?

\begin{frame}[label=working,t]
  \frametitle{Collision problem}
  
\end{frame}
\begin{frame}[label=working,t]
  \frametitle{Resolution: Latent identifiers}
  
\end{frame}
\begin{frame}[label=working,t]
  \frametitle{Results}
  
\end{frame}
\begin{frame}[label=working,t]
  \frametitle{Results (latency)}
  
\end{frame}

%backup slide: asymmetrical embeddings are important

\begin{frame}[label=working,t]
  \frametitle{Impact}
  \begin{itemize}
    \item strengths: low latency\checkmark, compact\checkmark,scaling to medium graphs\checkmark, weaknesses: training stability,expressiveness, scaling to \emph{very}large graphs
    \item \citep{vignacTopNEquivariantSet2021d} further analyzed the empirical observations, the impact of $\Phi$ and proposed an alternative latent parametrization
    \item \citep{martinkusSPECTRESpectralConditioning2022b} further improve the model with more powerful models and spectral conditioning, setting a new SotA in structure generation
  \end{itemize}
\end{frame}

\end{document}

